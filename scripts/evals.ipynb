{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fpod747AR9KD"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "G5qwSWEdfZBI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from utils import load_data, predict_formality, confusion_matrix, calculate_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRheKcgGR9KG"
      },
      "source": [
        "# Loading the Data\n",
        "\n",
        "Change the threshold value (0, 3) to alter the difficulty of the dataset. A low threshold signifies a more challenging classification task, while a high threshold will produce a simpler classification.\n",
        "\n",
        "Note that the threshold value also directly controls the size of the dataset (consult the documentation for an explanation of this)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_GB9OTUZgPXu"
      },
      "outputs": [],
      "source": [
        "threshold = 1.5\n",
        "train_df, test_df = load_data()\n",
        "\n",
        "df = pd.concat([train_df, test_df])\n",
        "\n",
        "binary_df = df[df['avg_score'].abs() > threshold].copy()\n",
        "binary_df['formal'] = binary_df['avg_score'].apply(lambda x: 1 if x > 0 else 0) # cr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xisc1HXYR9KI"
      },
      "source": [
        "# Load Models and Generate Predictions\n",
        "\n",
        "### XLM-RoBERTa Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "26aXxtMHgSAY"
      },
      "outputs": [],
      "source": [
        "# Loading the model from Hugging Face\n",
        "xlmr_tokenizer = AutoTokenizer.from_pretrained(\"s-nlp/xlmr_formality_classifier\")\n",
        "xlmr_model = AutoModelForSequenceClassification.from_pretrained(\"s-nlp/xlmr_formality_classifier\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAyxm0JhgdZb",
        "outputId": "ce4ee990-e82a-47bb-aa74-c2c94d0b7b12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 843/843 [01:34<00:00,  8.95it/s]\n"
          ]
        }
      ],
      "source": [
        "# Generating predictions on the binary (extreme) dataset\n",
        "xlmr_predicted_labels, xlmr_predicted_logits = predict_formality(xlmr_model, xlmr_tokenizer, binary_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vzm6BjbPR9KJ"
      },
      "source": [
        "### DistilBERT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "e5g4FA-kR9KJ"
      },
      "outputs": [],
      "source": [
        "distilbert_tokenizer = AutoTokenizer.from_pretrained('s-nlp/mdistilbert-base-formality-ranker')\n",
        "distilbert_model = AutoModelForSequenceClassification.from_pretrained('s-nlp/mdistilbert-base-formality-ranker')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4BsgGLGR9KK",
        "outputId": "be9faf26-7a47-4b96-aefe-2194a242f24c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 843/843 [00:52<00:00, 16.07it/s]\n"
          ]
        }
      ],
      "source": [
        "# Generating predictions on the binary (extreme) dataset\n",
        "distilbert_predicted_labels, distilbert_predicted_logits = predict_formality(distilbert_model, distilbert_tokenizer, binary_df, return_token_type_ids=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAoiErIzR9KK"
      },
      "source": [
        "### mDeBERTa Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v5APxnvMR9KK"
      },
      "outputs": [],
      "source": [
        "mdeberta_tokenizer = AutoTokenizer.from_pretrained('s-nlp/mdeberta-base-formality-ranker')\n",
        "mdeberta_model = AutoModelForSequenceClassification.from_pretrained('s-nlp/mdeberta-base-formality-ranker')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUv-xXJKR9KK",
        "outputId": "ccdc8b36-b7b8-48af-fa67-adfe28e05b96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 143/143 [00:05<00:00, 24.27it/s]\n"
          ]
        }
      ],
      "source": [
        "mdeberta_predicted_labels, mdeberta_predicted_logits = predict_formality(mdeberta_model, mdeberta_tokenizer, binary_df, padding=True, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4rHBHKfR9KK"
      },
      "source": [
        "### DeBERTa Large Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_xJFuYgxR9KK"
      },
      "outputs": [],
      "source": [
        "# Loading the model from Hugging Face\n",
        "deberta_large_tokenizer = AutoTokenizer.from_pretrained('s-nlp/deberta-large-formality-ranker')\n",
        "deberta_large_model = AutoModelForSequenceClassification.from_pretrained('s-nlp/deberta-large-formality-ranker')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdHuGkwVR9KL",
        "outputId": "a5ec3554-d90d-454e-929f-f21ae44cba50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3369/3369 [10:21<00:00,  5.42it/s]\n"
          ]
        }
      ],
      "source": [
        "# Generating predictions on the binary (extreme) dataset\n",
        "deberta_large_predicted_labels, deberta_large_predicted_logits = predict_formality(deberta_large_model, deberta_large_tokenizer, binary_df, batch_size=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sEo8_bER9KL"
      },
      "source": [
        "# Calculate Metrics (Binary Classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThYXXZegR9KL"
      },
      "source": [
        "### XLM-RoBERTa Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KezQVMLVKNOg",
        "outputId": "ec881a7f-f51d-4222-ac0a-e8b076a0dd5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XLM-RoBERTa Model Confusion Matrix:\n",
            "[[1267  642]\n",
            " [  11 1449]]\n",
            "XLM-RoBERTa Model Metrics:\n",
            "Accuracy: 0.8062\n",
            "Precision: 0.6930\n",
            "Recall: 0.9925\n",
            "F1 Score: 0.8161\n"
          ]
        }
      ],
      "source": [
        "xlmr_confusion_matrix = confusion_matrix(binary_df['formal'].values, xlmr_predicted_labels)\n",
        "xlmr_accuracy, xlmr_precision, xlmr_recall, xlmr_f1 = calculate_metrics(binary_df['formal'].values, xlmr_predicted_labels)\n",
        "\n",
        "print(\"XLM-RoBERTa Model Confusion Matrix:\")\n",
        "print(xlmr_confusion_matrix)\n",
        "\n",
        "print(f\"XLM-RoBERTa Model Metrics:\")\n",
        "print(f\"Accuracy: {xlmr_accuracy:.4f}\")\n",
        "print(f\"Precision: {xlmr_precision:.4f}\")\n",
        "print(f\"Recall: {xlmr_recall:.4f}\")\n",
        "print(f\"F1 Score: {xlmr_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP2oGngOR9KL"
      },
      "source": [
        "### DistilBERT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjgnXvyAR9KM",
        "outputId": "c5875f60-261f-44f5-9e1e-0b7751493ca6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBERT Model Confusion Matrix:\n",
            "[[1305  604]\n",
            " [  18 1442]]\n",
            "DistilBERT Model Metrics:\n",
            "Accuracy: 0.8154\n",
            "Precision: 0.7048\n",
            "Recall: 0.9877\n",
            "F1 Score: 0.8226\n"
          ]
        }
      ],
      "source": [
        "distilbert_confusion_matrix = confusion_matrix(binary_df['formal'].values, distilbert_predicted_labels)\n",
        "distilbert_accuracy, distilbert_precision, distilbert_recall, distilbert_f1 = calculate_metrics(binary_df['formal'].values, distilbert_predicted_labels)\n",
        "\n",
        "print(\"DistilBERT Model Confusion Matrix:\")\n",
        "print(distilbert_confusion_matrix)\n",
        "\n",
        "print(f\"DistilBERT Model Metrics:\")\n",
        "print(f\"Accuracy: {distilbert_accuracy:.4f}\")\n",
        "print(f\"Precision: {distilbert_precision:.4f}\")\n",
        "print(f\"Recall: {distilbert_recall:.4f}\")\n",
        "print(f\"F1 Score: {distilbert_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGel0dHJR9KM"
      },
      "source": [
        "### mDeBERTA Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "v-oTqS93R9KM",
        "outputId": "4c72c49b-fd1d-4f48-99e0-44349162fb93"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [3369, 572]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-3ff302e7c344>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmdeberta_confusion_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'formal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdeberta_predicted_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmdeberta_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdeberta_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdeberta_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdeberta_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'formal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdeberta_predicted_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mDeBERTA Base Model Confusion Matrix:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmdeberta_confusion_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \"\"\"\n\u001b[1;32m    339\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattach_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \"\"\"\n\u001b[1;32m     97\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [3369, 572]"
          ]
        }
      ],
      "source": [
        "mdeberta_confusion_matrix = confusion_matrix(binary_df['formal'].values, mdeberta_predicted_labels)\n",
        "mdeberta_accuracy, mdeberta_precision, mdeberta_recall, mdeberta_f1 = calculate_metrics(binary_df['formal'].values, mdeberta_predicted_labels)\n",
        "\n",
        "print(\"mDeBERTA Base Model Confusion Matrix:\")\n",
        "print(mdeberta_confusion_matrix)\n",
        "\n",
        "print(f\"mDeBERTA Base Model Metrics:\")\n",
        "print(f\"Accuracy: {mdeberta_accuracy:.4f}\")\n",
        "print(f\"Precision: {mdeberta_precision:.4f}\")\n",
        "print(f\"Recall: {mdeberta_recall:.4f}\")\n",
        "print(f\"F1 Score: {mdeberta_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lxuZGskR9KM"
      },
      "source": [
        "### DeBERTa Large Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpi478g2R9KM",
        "outputId": "f335b963-fc86-456d-da9f-eca365630c3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DeBERTa Large Model Confusion Matrix:\n",
            "[[1477  432]\n",
            " [  22 1438]]\n",
            "DeBERTa Large Model Metrics:\n",
            "Accuracy: 0.8652\n",
            "Precision: 0.7690\n",
            "Recall: 0.9849\n",
            "F1 Score: 0.8637\n"
          ]
        }
      ],
      "source": [
        "deberta_large_confusion_matrix = confusion_matrix(binary_df['formal'].values, deberta_large_predicted_labels)\n",
        "deberta_large_accuracy, deberta_large_precision, deberta_large_recall, deberta_large_f1 = calculate_metrics(binary_df['formal'].values, deberta_large_predicted_labels)\n",
        "\n",
        "print(\"DeBERTa Large Model Confusion Matrix:\")\n",
        "print(deberta_large_confusion_matrix)\n",
        "\n",
        "print(f\"DeBERTa Large Model Metrics:\")\n",
        "print(f\"Accuracy: {deberta_large_accuracy:.4f}\")\n",
        "print(f\"Precision: {deberta_large_precision:.4f}\")\n",
        "print(f\"Recall: {deberta_large_recall:.4f}\")\n",
        "print(f\"F1 Score: {deberta_large_f1:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}